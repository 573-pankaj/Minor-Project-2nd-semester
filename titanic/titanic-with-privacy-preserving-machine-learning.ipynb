{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> üëãüõ≥Ô∏è Hello here from the Machine Learning team at <a href=\"https://github.com/zama-ai/concrete-ml\">Zama</a></h1>\n",
    "\n",
    "We're happy to submit our participation in this Kaggle competition. Our main idea was not only to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù but also to do it on encrypted data. This was possible thanks to our Python package: <a href=\"https://github.com/zama-ai/concrete-ml\">Concrete-ML</a> that aims to simplify the use of fully homomorphic encryption (FHE) for data scientists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Machine Learning on Titanic\n",
    "\n",
    "This notebook introduces a Privacy-Preserving Machine Learning (PPML) solution to the [Kaggle Titanic competition](https://www.kaggle.com/c/titanic/) using the [Concrete-ML](https://docs.zama.ai/concrete-ml) open-source framework. Its main ambition is to show that [Fully Homomorphic Encryption](https://en.wikipedia.org/wiki/Homomorphic_encryption) (FHE) can be used for protecting data when using a Machine Learning model to predict outcomes without degrading its performance. In this example, a [XGBoost](https://xgboost.readthedocs.io/en/stable/) classifier model will be considered as it achieves near state-of-the-art accuracy.\n",
    "\n",
    "With inspiration from the [ppxgboost repository](https://github.com/awslabs/privacy-preserving-xgboost-inference/blob/master/example/Titanic.ipynb), which is \"Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. SPDX-License-Identifier: Apache-2.0\".\n",
    "\n",
    "It also took some ideas from several upvoted public notebooks, including [this one](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/notebook) from Manav Sehgal and [this one](https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy#Step-3:-Prepare-Data-for-Consumption) from LD Freeman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting concrete-ml\n",
      "  Using cached concrete_ml-0.2.1-py3-none-any.whl (66 kB)\n",
      "Collecting concrete-numpy[full]<0.6.0,>=0.5.0\n",
      "  Using cached concrete_numpy-0.5.0-py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.8.0 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (1.8.1)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.11.0 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (1.11.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.3 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (1.22.4)\n",
      "Collecting concrete-ml-extensions-hb[onnx]<0.5.0,>=0.4.2\n",
      "  Using cached concrete_ml_extensions_hb-0.4.2.2-py2.py3-none-any.whl (152 kB)\n",
      "Collecting onnx==1.11.0\n",
      "  Using cached onnx-1.11.0-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (58.0.4)\n",
      "Requirement already satisfied: xgboost<2.0.0,>=1.5.2 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (1.6.1)\n",
      "Requirement already satisfied: protobuf==3.19.4 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (3.19.4)\n",
      "Collecting skorch<0.12.0,>=0.11.0\n",
      "  Using cached skorch-0.11.0-py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.2 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-ml) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from onnx==1.11.0->concrete-ml) (4.1.1)\n",
      "Collecting onnxconverter-common>=1.6.0\n",
      "  Using cached onnxconverter_common-1.12.1-py2.py3-none-any.whl (83 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Collecting psutil\n",
      "  Using cached psutil-5.9.1-cp39-cp39-win_amd64.whl (245 kB)\n",
      "Collecting onnxruntime>=1.0.0\n",
      "  Using cached onnxruntime-1.12.1-cp39-cp39-win_amd64.whl (5.8 MB)\n",
      "Collecting skl2onnx>=1.7.0\n",
      "  Using cached skl2onnx-1.12-py2.py3-none-any.whl (279 kB)\n",
      "Collecting onnxmltools>=1.6.0\n",
      "  Using cached onnxmltools-1.11.1-py3-none-any.whl (308 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.5.1 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-numpy[full]<0.6.0,>=0.5.0->concrete-ml) (3.5.2)\n",
      "INFO: pip is looking at multiple versions of concrete-ml-extensions-hb[onnx] to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting protobuf==3.19.4\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "INFO: pip is looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of concrete-ml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting concrete-ml\n",
      "  Using cached concrete_ml-0.2.0-py3-none-any.whl (67 kB)\n",
      "Collecting onnx<2.0.0,>=1.11.0\n",
      "  Using cached onnx-1.12.0-cp39-cp39-win_amd64.whl (11.5 MB)\n",
      "Collecting concrete-ml\n",
      "  Using cached concrete_ml-0.1.1-py3-none-any.whl (66 kB)\n",
      "Collecting concrete-numpy[full]<0.5.0,>=0.4.0\n",
      "  Using cached concrete_numpy-0.4.0-py3-none-any.whl (91 kB)\n",
      "Collecting loguru<0.6.0,>=0.5.3\n",
      "  Using cached loguru-0.5.3-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: networkx<3.0.0,>=2.6.3 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-numpy[full]<0.5.0,>=0.4.0->concrete-ml) (2.8)\n",
      "Requirement already satisfied: Pillow<10.0.0,>=9.0.0 in c:\\users\\panka\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from concrete-numpy[full]<0.5.0,>=0.4.0->concrete-ml) (9.0.1)\n",
      "Collecting concrete-ml\n",
      "  Using cached concrete_ml-0.1.0-py3-none-any.whl (66 kB)\n",
      "Collecting concrete-numpy[full]<0.4.0,>=0.3.0\n",
      "  Using cached concrete_numpy-0.3.0-py3-none-any.whl (91 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement concrete-compiler<0.5.0,>=0.4.0 (from concrete-numpy[full]) (from versions: none)\n",
      "ERROR: No matching distribution found for concrete-compiler<0.5.0,>=0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install concrete-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'concrete'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24860/834662671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mConcreteXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'concrete'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from concrete.ml.sklearn import XGBClassifier as ConcreteXGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install concrete-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to run `make download_datasets` to have local versions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the datasets\n",
    "# if not Path(\"./local_datasets/titanic/train.csv\").is_file():\n",
    "#     raise ValueError(\"Please download the datasets by running `make download_datasets`.\")\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "datasets = [train_data, test_data]\n",
    "\n",
    "# Save the passenger IDs used for submission\n",
    "test_ids = test_data[\"PassengerId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   \t| PassengerId \t| Survived \t| Pclass \t|                                              Name \t|    Sex \t|  Age \t| SibSp \t| Parch \t|           Ticket \t|    Fare \t| Cabin \t| Embarked \t|\n",
    "|--:\t|------------:\t|---------:\t|-------:\t|--------------------------------------------------:\t|-------:\t|-----:\t|------:\t|------:\t|-----------------:\t|--------:\t|------:\t|---------:\t|\n",
    "| 0 \t|           1 \t|        0 \t|      3 \t|                           Braund, Mr. Owen Harris \t|   male \t| 22.0 \t|     1 \t|     0 \t|        A/5 21171 \t|  7.2500 \t|   NaN \t|        S \t|\n",
    "| 1 \t|           2 \t|        1 \t|      1 \t| Cumings, Mrs. John Bradley (Florence Briggs Th... \t| female \t| 38.0 \t|     1 \t|     0 \t|         PC 17599 \t| 71.2833 \t|   C85 \t|        C \t|\n",
    "| 2 \t|           3 \t|        1 \t|      3 \t|                            Heikkinen, Miss. Laina \t| female \t| 26.0 \t|     0 \t|     0 \t| STON/O2. 3101282 \t|  7.9250 \t|   NaN \t|        S \t|\n",
    "| 3 \t|           4 \t|        1 \t|      1 \t|      Futrelle, Mrs. Jacques Heath (Lily May Peel) \t| female \t| 35.0 \t|     1 \t|     0 \t|           113803 \t| 53.1000 \t|  C123 \t|        S \t|\n",
    "| 4 \t|           5 \t|        0 \t|      3 \t|                          Allen, Mr. William Henry \t|   male \t| 35.0 \t|     0 \t|     0 \t|           373450 \t|  8.0500 \t|   NaN \t|        S \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe:\n",
    "- the target variable: Survived\n",
    "- some numerical variables: PassengerID, Pclass, SbSp, Parch, Fare\n",
    "- some categorical (non-numerical) variables: Name, Sex, Ticket, Cabin, Embarked\n",
    "\n",
    "First, it seems that PassengerId and Ticket are supposed to be random Ids that should not impact the predictions so we can already remove them from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column = [\"PassengerId\", \"Ticket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Then, we can notice that some values are missing for the Cabin variable. We must therefore investigate a bit more about this by printing the total amounts of missing values for each variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train data ---\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64 \n",
      "\n",
      "--- Test data ---\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 3, \"Train data\", \"-\" * 3)\n",
    "print(train_data.isnull().sum(), \"\\n\")\n",
    "print(\"-\" * 3, \"Test data\", \"-\" * 3)\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Training Data \t|     \t|\n",
    "|---------------\t|-----\t|\n",
    "| PassengerId   \t| 0   \t|\n",
    "| Survived      \t| 0   \t|\n",
    "| Pclass        \t| 0   \t|\n",
    "| Name          \t| 0   \t|\n",
    "| Sex           \t| 0   \t|\n",
    "| Age           \t| 177 \t|\n",
    "| SibSp         \t| 0   \t|\n",
    "| Parch         \t| 0   \t|\n",
    "| Ticket        \t| 0   \t|\n",
    "| Fare          \t| 0   \t|\n",
    "| Cabin         \t| 687 \t|\n",
    "| Embarked      \t| 2   \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Test Data     \t|     \t|\n",
    "|---------------\t|-----\t|\n",
    "| PassengerId   \t| 0   \t|\n",
    "| Pclass        \t| 0   \t|\n",
    "| Name          \t| 0   \t|\n",
    "| Sex           \t| 0   \t|\n",
    "| Age           \t| 86  \t|\n",
    "| SibSp         \t| 0   \t|\n",
    "| Parch         \t| 0   \t|\n",
    "| Ticket        \t| 0   \t|\n",
    "| Fare          \t| 1   \t|\n",
    "| Cabin         \t| 327 \t|\n",
    "| Embarked      \t| 0   \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in Age: 20.1%\n",
      "Percentage of missing values in Fare: 0.1%\n",
      "Percentage of missing values in Cabin: 77.5%\n",
      "Percentage of missing values in Embarked: 0.2%\n"
     ]
    }
   ],
   "source": [
    "for incomp_var in train_data.columns:\n",
    "    missing_val = pd.concat(datasets)[incomp_var].isnull().sum()\n",
    "    if missing_val > 0 and incomp_var != \"Survived\":\n",
    "        total_val = pd.concat(datasets).shape[0]\n",
    "        print(f\"Percentage of missing values in {incomp_var}: {missing_val/total_val*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of missing values in Age: 20.1%\n",
    "\n",
    "Percentage of missing values in Fare: 0.1%\n",
    "\n",
    "Percentage of missing values in Cabin: 77.5%\n",
    "\n",
    "Percentage of missing values in Embarked: 0.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only four variables are incomplete: Cabin, Age, Embarked and Fare. However, the Cabin one seems to be missing quite more data than the others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Cabin variable misses more than 2/3 of its values, it might not be relevant to keep it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column += [\"Cabin\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Remove irrelevant variables\n",
    "    dataset.drop(drop_column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other ones, we can replace the missing values using:\n",
    "- the median value for Age and Fare\n",
    "- the most common value for Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    # Complete missing Age values with median\n",
    "    dataset.Age.fillna(dataset.Age.median(), inplace=True)\n",
    "\n",
    "    # Complete missing Embarked values with the most common one\n",
    "    dataset.Embarked.fillna(dataset.Embarked.mode()[0], inplace=True)\n",
    "\n",
    "    # Complete missing Fare values with median\n",
    "    dataset.Fare.fillna(dataset.Fare.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We can manually extract and create new features in order to help the model interpret some behaviors and correctly predict an outcome. Those new features are:\n",
    "- FamilySize: The size of the family the individual was traveling with, with 1 being someone that traveled alone. \n",
    "- IsAlone: A boolean variable stating if the individual was traveling alone (1) or not (0). This might help the model to emphasize on this idea of traveling with relatives or not.\n",
    "- Title: The individual's title (Mr, Mrs, ...), often indicating a certain social status.\n",
    "- Farebin and AgeBin: Binned version of the Fare and Age variables. It groups values together, generally reducing the impact of minor observation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panka\\AppData\\Local\\Temp/ipykernel_24860/3729089738.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.IsAlone[dataset.FamilySize > 1] = 0\n",
      "C:\\Users\\panka\\AppData\\Local\\Temp/ipykernel_24860/3729089738.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.IsAlone[dataset.FamilySize > 1] = 0\n"
     ]
    }
   ],
   "source": [
    "def get_bin_labels(bin_name, number_of_bins):\n",
    "    labels = []\n",
    "    for i in range(number_of_bins):\n",
    "        labels.append(bin_name + f\"_{i}\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Emphasize on relatives\n",
    "    dataset[\"FamilySize\"] = dataset.SibSp + dataset.Parch + 1\n",
    "\n",
    "    dataset[\"IsAlone\"] = 1\n",
    "    dataset.IsAlone[dataset.FamilySize > 1] = 0\n",
    "\n",
    "    # Consider an individual's social status\n",
    "    dataset[\"Title\"] = dataset.Name.str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n",
    "\n",
    "    # Group fares and ages in \"bins\" or \"buckets\"\n",
    "    dataset[\"FareBin\"] = pd.qcut(dataset.Fare, 4, labels=get_bin_labels(\"FareBin\", 4))\n",
    "    dataset[\"AgeBin\"] = pd.cut(dataset.Age.astype(int), 5, labels=get_bin_labels(\"AgeBin\", 5))\n",
    "\n",
    "    # Remove now-irrelevant variables\n",
    "    drop_column = [\"Name\", \"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n",
    "    dataset.drop(drop_column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on the titles' distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          757\n",
      "Miss        260\n",
      "Mrs         197\n",
      "Master       61\n",
      "Rev           8\n",
      "Dr            8\n",
      "Col           4\n",
      "Mlle          2\n",
      "Major         2\n",
      "Ms            2\n",
      "Lady          1\n",
      "Sir           1\n",
      "Mme           1\n",
      "Don           1\n",
      "Capt          1\n",
      "Countess      1\n",
      "Jonkheer      1\n",
      "Dona          1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat(datasets)\n",
    "titles = data.Title.value_counts()\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Titles  \t| Counts  \t|\n",
    "|----------\t|-----\t|\n",
    "| Mr       \t| 757 \t|\n",
    "| Miss     \t| 260 \t|\n",
    "| Mrs      \t| 197 \t|\n",
    "| Master   \t| 61  \t|\n",
    "| Rev      \t| 8   \t|\n",
    "| Dr       \t| 8   \t|\n",
    "| Col      \t| 4   \t|\n",
    "| Mlle     \t| 2   \t|\n",
    "| Major    \t| 2   \t|\n",
    "| Ms       \t| 2   \t|\n",
    "| Lady     \t| 1   \t|\n",
    "| Sir      \t| 1   \t|\n",
    "| Mme      \t| 1   \t|\n",
    "| Don      \t| 1   \t|\n",
    "| Capt     \t| 1   \t|\n",
    "| Countess \t| 1   \t|\n",
    "| Jonkheer \t| 1   \t|\n",
    "| Dona     \t| 1   \t|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly observe that only a few titles represent most of the individuals. In order to prevent the model from becoming overly specific, we decide to group all the \"uncommon\" titles together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommon_titles = titles[titles < 10].index\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.Title.replace(uncommon_titles, \"Rare\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummification\n",
    "\n",
    "Finally, we can \"dummify\" the remaining categorical variables. Dummification is a common technique of transforming categorical (non-numerical) data into numerical data without having to map values or consider any order between each of them. The idea is to take all the different values found in a variable and create a new associated binary variable. \n",
    "\n",
    "For example, the \"Embarked\" variable has three categorical values: \"S\", \"C\" and \"Q\". Dummifying the data will create three new variables, \"Embarked_S\", \"Embarked_C\" and \"Embarked_Q\", and set the value of \"Embarked_S\" (resp. \"Embarked_C\" and \"Embarked_Q\") to 1 for each data point initially labeled with \"S\" (resp. \"C\" and \"Q\") in the \"Embarked\" variable, else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = train_data.select_dtypes(exclude=np.number).columns\n",
    "x_train = pd.get_dummies(train_data, prefix=categorical_features)\n",
    "x_test = pd.get_dummies(test_data, prefix=categorical_features).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the target variable from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "x_train = x_train.drop(columns=[target])\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = train_data[target].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "### Training with XGBoost\n",
    "\n",
    "Let's first train a classifier model using XGBoost. Since several parameters have to be fixed beforehand, we use scikit-learn's GridSearchCV method to perform cross validation in order to maximize our chance to find the best ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found in 4.84s : {'learning_rate': 1, 'max_depth': 4, 'n_estimators': 4}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Cross-Validation generator\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "\n",
    "# Set the parameters to tune.\n",
    "# Those ranges are voluntarily small in order to keep the FHE execution time per inference\n",
    "# relatively low. In fact, we found out that, in this particular Titanic example, models with\n",
    "# larger numbers of estimators or maximum depth don't score a much better accuracy.\n",
    "param_grid = {\n",
    "    \"max_depth\": list(range(1, 5)),\n",
    "    \"n_estimators\": list(range(1, 5)),\n",
    "    \"learning_rate\": [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Instantiate and fit the model through grid-search cross-validation\n",
    "time_begin = time.time()\n",
    "model = GridSearchCV(XGBClassifier(), param_grid, cv=cv, scoring=\"roc_auc\")\n",
    "model.fit(x_train, y_train)\n",
    "cv_xgb_duration = time.time() - time_begin\n",
    "\n",
    "print(f\"Best hyperparameters found in {cv_xgb_duration:.2f}s :\", model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters found in 4.40s : {'learning_rate': 1, 'max_depth': 4, 'n_estimators': 4}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Concrete-ML\n",
    "\n",
    "Now, let's do the same with Concrete-ML's XGBClassifier method. \n",
    "\n",
    "In order to do so, we need to specify the number of bits over which inputs, outputs and weights will be quantized. This value can influence the precision of the model as well as its inference running time, and therefore can lead the grid-search cross-validation to find a different set of parameters. In our case, setting this value to 2 bits outputs an excellent accuracy score while running faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConcreteXGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24860/1937621264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Instantiate and fit the model through grid-search cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtime_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mconcrete_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConcreteXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"roc_auc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mconcrete_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcv_concrete_duration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_begin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ConcreteXGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# The Concrete-ML model needs an additional parameter used for quantization\n",
    "param_grid[\"n_bits\"] = [2]\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "\n",
    "# Instantiate and fit the model through grid-search cross-validation\n",
    "time_begin = time.time()\n",
    "concrete_model = GridSearchCV(ConcreteXGBClassifier(), param_grid, cv=cv, scoring=\"roc_auc\")\n",
    "concrete_model.fit(x_train, y_train)\n",
    "cv_concrete_duration = time.time() - time_begin\n",
    "\n",
    "print(f\"Best hyperparameters found in {cv_concrete_duration:.2f}s :\", concrete_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters found in 32.79s : {'learning_rate': 0.1, 'max_depth': 4, 'n_bits': 2, 'n_estimators': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the predictions in FHE on the complete test set of 418 data points using the above hyperparameters can take up to 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions in clear using XGBoost\n",
    "clear_predictions = model.predict(x_test)\n",
    "\n",
    "# Compute the predictions in clear using Concrete-ML\n",
    "clear_quantized_predictions = concrete_model.predict(x_test)\n",
    "\n",
    "# Compile the Concrete-ML model on a subset\n",
    "concrete_model.best_estimator_.compile(x_train[:100])\n",
    "\n",
    "# Generate the keys\n",
    "# This step is not necessary, keygen() is called directly within the predict method. However, since\n",
    "# the keys are stored in cache by default, it is useful to run it beforehand in order to be able to\n",
    "# measure the prediction executing time separately from the key generation one\n",
    "time_begin = time.time()\n",
    "concrete_model.best_estimator_.fhe_tree.keygen()\n",
    "key_generation_duration = time.time() - time_begin\n",
    "\n",
    "# Compute the predictions in FHE using Concrete-ML\n",
    "# Giving x_test as an input to the predict method is possible in Concrete-ML but without the use of\n",
    "# batches. We therefore decided to directly loop over it in order to better visualize the progress\n",
    "# using the tqdm package, as it doesn't impact the overall execution time.\n",
    "fhe_predictions = []\n",
    "time_begin = time.time()\n",
    "for data_point in tqdm(x_test):\n",
    "    fhe_predictions.append(\n",
    "        concrete_model.best_estimator_.predict(np.array([data_point]), execute_in_fhe=True)[0]\n",
    "    )\n",
    "prediction_duration = time.time() - time_begin\n",
    "\n",
    "print(f\"Key generation time: {key_generation_duration:.2f}s\")\n",
    "print(f\"Total execution time for {len(clear_predictions)} inferences: {prediction_duration:.2f}s\")\n",
    "print(f\"Execution time per inference in FHE : {prediction_duration / len(clear_predictions):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 418/418 [18:58<00:00,  2.72s/it]\n",
    "\n",
    "Key generation time: 12.00s\n",
    "\n",
    "Total execution time for 418 inferences: 1138.80s\n",
    "\n",
    "Execution time per inference in FHE : 2.72s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FHE computations are expected to be exact. This means that the model executed in FHE results in the same predictions as the Concrete-ML one, which is executed in clear and only considers quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_equal_preds = np.sum(fhe_predictions == clear_quantized_predictions)\n",
    "pred_similarity = number_of_equal_preds / len(clear_predictions) * 100\n",
    "print(\n",
    "    \"Prediction similarity between both Concrete-ML models (quantized clear and FHE): \"\n",
    "    f\"{pred_similarity:.2f}%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction similarity between both Concrete-ML models (quantized clear and FHE): 100.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as seen previously, the grid-search cross-validation was done separately between the XGBoost model and the Concrete-ML one. For this reason, the two models do not share the same set of hyperparameters, making their decision boundaries different.\n",
    "\n",
    "Comparing how similar their predictions are one by one is thus irrelevant and only the final accuracy score given by the Kaggle platform should be considered to assess their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Kaggle Submission File\n",
    "\n",
    "When [submitted](https://www.kaggle.com/competitions/titanic/submit) to the Kaggle platform, the FHE model outputs an accuracy of 78% ([leaderboard](https://www.kaggle.com/competitions/titanic/leaderboard?search=concrete)). In comparison, the XGBoost clear one also scores around 77%.\n",
    "\n",
    "In fact, using the given dataset, most of the submitted notebooks do not seem to exceed 79% of accuracy. Therefore, additional pre-processing and feature engineering might help increase our current score but probably not by much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the FHE predictions\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"PassengerId\": test_ids,\n",
    "        \"Survived\": fhe_predictions,\n",
    "    }\n",
    ")\n",
    "submission.to_csv(\"titanic_submission_fhe.csv\", index=False)\n",
    "\n",
    "# Save the XGBoost clear predictions\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"PassengerId\": test_ids,\n",
    "        \"Survived\": clear_predictions,\n",
    "    }\n",
    ")\n",
    "submission.to_csv(\"titanic_submission_xgb_clear.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "If you liked this work, please have a look to our repo: **we're open source!**\n",
    "<br/>\n",
    "‚≠êÔ∏è Star us on Github here: <a href=\"https://github.com/zama-ai/concrete-ml\" target=\"_blank\">github.com/zama-ai/concrete-ml</a>\n",
    "<br/>\n",
    "üëã And ask us anything on our community forum: <a href=\"https://community.zama.ai/c/concrete-ml/8?utm_source=participation&utm_medium=titanic&utm_campaign=kaggle\" target=\"_blank\">community.zama.ai</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
