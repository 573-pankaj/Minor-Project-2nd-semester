{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homomorphic Encryption Basic Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import phe as paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Public and Private Keys\n",
    "key_length = 1024\n",
    "pub_key, private_key = paillier.generate_paillier_keypair(n_length=key_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaillierPublicKey 75fbaa8754>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaillierPrivateKey for <PaillierPublicKey 75fbaa8754>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  10\n",
      "Encrypted a:  <phe.paillier.EncryptedNumber object at 0x00000258B33A6DF0>\n",
      "Encrypted a Public Key:  <PaillierPublicKey 75fbaa8754>\n"
     ]
    }
   ],
   "source": [
    "# Encrypt an operation using Public Key\n",
    "a = 10\n",
    "print(\"a: \",a)\n",
    "\n",
    "encrypted_a = pub_key.encrypt(a)\n",
    "print(\"Encrypted a: \",encrypted_a)\n",
    "\n",
    "print(\"Encrypted a Public Key: \", encrypted_a.public_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:  5\n",
      "Encrypted b:  <phe.paillier.EncryptedNumber object at 0x00000258B3396E20>\n",
      "Encrypted b Public Key:  <PaillierPublicKey 75fbaa8754>\n"
     ]
    }
   ],
   "source": [
    "# Encrypt another variable\n",
    "b = 5\n",
    "print(\"b: \", b)\n",
    "\n",
    "encrypted_b = pub_key.encrypt(b)\n",
    "print(\"Encrypted b: \", encrypted_b)\n",
    "\n",
    "print(\"Encrypted b Public Key: \",encrypted_b.public_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  15\n"
     ]
    }
   ],
   "source": [
    "# Do an operation on Encrypted Variables\n",
    "c = a + b\n",
    "print(\"c: \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:  50\n"
     ]
    }
   ],
   "source": [
    "d = a * b\n",
    "print(\"d: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted e:  <phe.paillier.EncryptedNumber object at 0x00000258B33A6AF0>\n"
     ]
    }
   ],
   "source": [
    "e = a - b\n",
    "\n",
    "encrypted_e = pub_key.encrypt(e)\n",
    "print(\"Encrypted e: \", encrypted_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrypt the Encrypted Data\n",
    "decrypted_e = private_key.decrypt(encrypted_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrypted e:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Decrypted e: \", decrypted_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homomorphic Encryption for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression for Spam/Not Spam e-mail Classification.\n",
    "\n",
    "For this problem we have two users:\n",
    "\n",
    "**USER-1**\n",
    "\n",
    "**USER-2**\n",
    "\n",
    "AI Inc. makes a Machine Learning model that is trained on some email data for classification between Spam/Not Spam. Now, they want to take that model, encrypt it and send to USER-1 and USER-2 who will train the model on their data, fully Homomorphically Encrypted, and send the trained, a bit better model back to AI Inc.\n",
    "\n",
    "In this process, AI Inc. get a better trained model every time without even looking at USER-1 or USER-2 data. This way AI Inc. can serve the customers better with a smart Machine Learning model and the USER has complete control of his/her data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import time\n",
    "import os.path\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_data():\n",
    "    \"\"\"\n",
    "    Load the email dataset and Represent them as bag-of-words.\n",
    "    Shuffle and split train/test.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Importing dataset...\")\n",
    "    path = './dataset/enron1/ham/'\n",
    "    ham1 = [open(path + f, 'r', errors='replace').read().strip(r\"\\n\")\n",
    "            for f in os.listdir(path) if os.path.isfile(path + f)]\n",
    "    path = './dataset/enron1/spam/'\n",
    "    spam1 = [open(path + f, 'r', errors='replace').read().strip(r\"\\n\")\n",
    "             for f in os.listdir(path) if os.path.isfile(path + f)]\n",
    "    path = './dataset/enron2/ham/'\n",
    "    ham2 = [open(path + f, 'r', errors='replace').read().strip(r\"\\n\")\n",
    "            for f in os.listdir(path) if os.path.isfile(path + f)]\n",
    "    path = './dataset/enron2/spam/'\n",
    "    spam2 = [open(path + f, 'r', errors='replace').read().strip(r\"\\n\")\n",
    "             for f in os.listdir(path) if os.path.isfile(path + f)]\n",
    "\n",
    "    # Merge and create labels\n",
    "    emails = ham1 + spam1 + ham2 + spam2\n",
    "    y = np.array([-1] * len(ham1) + [1] * len(spam1) +\n",
    "                 [-1] * len(ham2) + [1] * len(spam2))\n",
    "\n",
    "    # Words count, keep only frequent words\n",
    "    # Minimum Document Word Frequency: 0.001\n",
    "    count_vect = CountVectorizer(decode_error='replace', stop_words='english', min_df=0.001)\n",
    "    X = count_vect.fit_transform(emails)\n",
    "\n",
    "    print('Vocabulary size: %d' % X.shape[1])\n",
    "\n",
    "    # Shuffle\n",
    "    perm = np.random.permutation(X.shape[0])\n",
    "    X, y = X[perm, :], y[perm]\n",
    "\n",
    "    # Split train and test\n",
    "    split = 500\n",
    "    X_train, X_test = X[-split:, :], X[:-split, :]\n",
    "    y_train, y_test = y[-split:], y[:-split]\n",
    "\n",
    "    print(\"Labels in trainset are {:.2f} spam : {:.2f} ham\".format(\n",
    "        np.mean(y_train == 1), np.mean(y_train == -1)))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer():\n",
    "    \"\"\"Helper for measuring runtime\"\"\"\n",
    "\n",
    "    time0 = time.perf_counter()\n",
    "    yield\n",
    "    print('[elapsed time: %.2f s]' % (time.perf_counter() - time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Inc:\n",
    "    \"\"\"\n",
    "    AI Inc. Trains a Logistic Regression model on plaintext data, encrypts the model for remote use by USER-1 and USER-2,\n",
    "    decrypts encrypted scores using the paillier private key.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression()\n",
    "\n",
    "    # Generate Public and Private Key Pairs\n",
    "    # Public Key is used to Encrypt the Data, Private Key to Decrypt\n",
    "    def generate_paillier_keypair(self, n_length):\n",
    "        self.pubkey, self.privkey = paillier.generate_paillier_keypair(n_length=n_length)\n",
    "\n",
    "    # Train the Model\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.model.fit(X, y)\n",
    "\n",
    "    # Make Predictions for Email \"Spam/Not Spam\"\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    # Encypt the Coefficients for the Logistic Regression Equation\n",
    "    # Weights can tell about the data, so Encrypt them\n",
    "    # Equation: y = mX + b\n",
    "    def encrypt_weights(self):\n",
    "        coef = self.model.coef_[0, :]\n",
    "        encrypted_weights = [self.pubkey.encrypt(coef[i])\n",
    "                             for i in range(coef.shape[0])]\n",
    "        encrypted_intercept = self.pubkey.encrypt(self.model.intercept_[0])\n",
    "        return encrypted_weights, encrypted_intercept\n",
    "\n",
    "    # Decrypt the Scores for the Model\n",
    "    def decrypt_scores(self, encrypted_scores):\n",
    "        return [self.privkey.decrypt(s) for s in encrypted_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the USER-1 gets a trained model from AI Inc. and trains on its own data all using Homomorphic Encryption.\n",
    "class User_1:\n",
    "    \"\"\"\n",
    "    USER-1/USER-2 are given the encrypted model trained by AI Inc. and the public key.\n",
    "\n",
    "    Scores local plaintext data with the encrypted model, but cannot decrypt\n",
    "    the scores without the private key held by AI Inc..\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pubkey):\n",
    "        self.pubkey = pubkey\n",
    "\n",
    "    # Set Initial Values of Coefficients\n",
    "    def set_weights(self, weights, intercept):\n",
    "        self.weights = weights                      # here gets encripted weightd and encripted intercepts\n",
    "        self.intercept = intercept\n",
    "\n",
    "    # Compute the Prediction Scores for the Model all while being totally Encrypted.\n",
    "    def encrypted_score(self, x):\n",
    "        \"\"\"Compute the score of `x` by multiplying with the encrypted model,\n",
    "        which is a vector of `paillier.EncryptedNumber`\"\"\"\n",
    "        score = self.intercept\n",
    "        _, idx = x.nonzero()\n",
    "        for i in idx:\n",
    "            score += x[0, i] * self.weights[i]\n",
    "        return score\n",
    "\n",
    "    # Get the Evaluation Scores for the Model\n",
    "    def encrypted_evaluate(self, X):\n",
    "        return [self.encrypted_score(X[i, :]) for i in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './dataset/enron1/ham/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the Preprocessed Split Data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImporting dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/enron1/ham/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m ham1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path \u001b[38;5;241m+\u001b[39m f)]\n\u001b[0;32m     12\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/enron1/spam/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m spam1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mopen\u001b[39m(path \u001b[38;5;241m+\u001b[39m f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path \u001b[38;5;241m+\u001b[39m f)]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './dataset/enron1/ham/'"
     ]
    }
   ],
   "source": [
    "# Get the Preprocessed Split Data\n",
    "X_train, y_train, X_test, y_test = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now firstly the AI Inc. Generates the Public and Private Keys\n",
    "print(\"AI Inc.: Generating Paillier Public Private Keypair\")\n",
    "ai_inc = AI_Inc()    # object creation\n",
    "# NOTE: using smaller keys sizes wouldn't be cryptographically safe\n",
    "ai_inc.generate_paillier_keypair(n_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AI Inc.: Training Initial Spam Classifier\")\n",
    "with timer() as t:\n",
    "    ai_inc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AI Inc.'s Classification on Test Data, what it would expect the performance to be on USER-1/2's data...\")\n",
    "with timer() as t:\n",
    "    error = np.mean(ai_inc.predict(X_test) != y_test)\n",
    "print(\"Error {:.3f}\".format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AI Inc.: Encrypting Trained Classifier before sending to USER-1/2\")\n",
    "with timer() as t:\n",
    "    encrypted_weights, encrypted_intercept = ai_inc.encrypt_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming the Weights are Encrypted\n",
    "print(\"Encrypted Weights: \", encrypted_weights)\n",
    "print(\"Encrypted Intercept: \", encrypted_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have an encrypted trained model.\n",
    "\n",
    "AI Inc. sends the trained model with it's weights encrypted [as weights can tell something about the data] and sends both the things to the USER-1 and USER2.\n",
    "\n",
    "Now, USER-1 and USER-2 get the encrypted weights, the trained model and the public key to do some operations on their own dataset. This is called **Homomorphic Encryption**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-1 taking the encrypted model, weights and testing performance on it's own dataset\n",
    "print(\"USER-1: Scoring on own data with AI Inc.'s Encrypted Classifier...\")\n",
    "\n",
    "# AI Inc sends the Public Keys to perform operations\n",
    "user_1 = User_1(ai_inc.pubkey)\n",
    "\n",
    "# USER-1 sets the model Hyperparameters to AI Inc.'s Hyperparameter values\n",
    "user_1.set_weights(encrypted_weights, encrypted_intercept)\n",
    "\n",
    "with timer() as t:\n",
    "    encrypted_scores = user_1.encrypted_evaluate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Sure the Score is Encrypted\n",
    "print(encrypted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now USER has the option to train the model on it's own data and send the trained model to AI Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AI Inc.: Decrypting USER-1/2's scores\")\n",
    "\n",
    "with timer() as t:\n",
    "    scores = ai_inc.decrypt_scores(encrypted_scores)\n",
    "    error = np.mean(np.sign(scores) != y_test)\n",
    "print(\"Error {:.3f} -- this is not known to AI Inc., who does not possess the ground truth labels\".format(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
